{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd54e05-45e2-43ba-82b9-4f06162353e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Группа DS_07_P_online\n",
    "\n",
    "Cтудента ГГТУ им. П.О. Сухого, Романюка Е.И. гр. ИП-31.\n",
    "\n",
    "Домашнее задание номер 1-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f6315d-eadd-42f1-bdca-8910ab81c609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных слов: 180\n",
      "Гласные: 4867\n",
      "Согласные: 6283\n",
      "Количество предложений: 265\n",
      "Общая длина предложений: 2000\n",
      "Частота слов с учетом схожести:\n",
      "sit: 209\n",
      "nec: 129\n",
      "a: 97\n",
      "velit: 63\n",
      "lectus: 54\n",
      "duis: 51\n",
      "cras: 46\n",
      "amet: 44\n",
      "nisl: 41\n",
      "ante: 38\n",
      "etiam: 36\n",
      "orci: 35\n",
      "aliquam: 35\n",
      "vitae: 34\n",
      "mauris: 29\n",
      "tellus: 27\n",
      "nulla: 26\n",
      "pellentesque: 23\n",
      "ultrices: 21\n",
      "massa: 21\n",
      "faucibus: 17\n",
      "pulvinar: 17\n",
      "semper: 16\n",
      "cursus: 16\n",
      "sodales: 16\n",
      "tincidunt: 16\n",
      "lorem: 15\n",
      "ipsum: 15\n",
      "molestie: 15\n",
      "mollis: 15\n",
      "quam: 15\n",
      "vestibulum: 15\n",
      "dolor: 13\n",
      "venenatis: 13\n",
      "odio: 13\n",
      "sollicitudin: 13\n",
      "augue: 13\n",
      "consectetur: 12\n",
      "quisque: 12\n",
      "risus: 12\n",
      "eleifend: 12\n",
      "neque: 12\n",
      "integer: 12\n",
      "turpis: 12\n",
      "lobortis: 12\n",
      "varius: 12\n",
      "convallis: 12\n",
      "vulputate: 12\n",
      "scelerisque: 12\n",
      "maximus: 11\n",
      "laoreet: 11\n",
      "placerat: 11\n",
      "euismod: 11\n",
      "urna: 11\n",
      "dignissim: 11\n",
      "condimentum: 11\n",
      "posuere: 11\n",
      "suspendisse: 10\n",
      "congue: 10\n",
      "dictumst: 10\n",
      "porta: 10\n",
      "malesuada: 10\n",
      "feugiat: 10\n",
      "justo: 10\n",
      "rhoncus: 10\n",
      "tortor: 10\n",
      "phasellus: 10\n",
      "praesent: 9\n",
      "consequat: 9\n",
      "rutrum: 9\n",
      "ullamcorper: 9\n",
      "tristique: 9\n",
      "libero: 9\n",
      "auctor: 9\n",
      "bibendum: 9\n",
      "aenean: 9\n",
      "sagittis: 9\n",
      "commodo: 8\n",
      "facilisis: 8\n",
      "iaculis: 8\n",
      "interdum: 8\n",
      "sapien: 8\n",
      "lacinia: 8\n",
      "efficitur: 8\n",
      "finibus: 8\n",
      "proin: 8\n",
      "maecenas: 8\n",
      "pharetra: 7\n",
      "viverra: 7\n",
      "curabitur: 7\n",
      "accumsan: 7\n",
      "egestas: 7\n",
      "fringilla: 7\n",
      "vehicula: 6\n",
      "dapibus: 6\n",
      "ornare: 6\n",
      "hendrerit: 6\n",
      "ligula: 6\n",
      "fusce: 6\n",
      "volutpat: 6\n",
      "elementum: 6\n",
      "pretium: 5\n",
      "gravida: 5\n",
      "suscipit: 5\n",
      "fermentum: 5\n",
      "aptent: 5\n",
      "taciti: 5\n",
      "sociosqu: 5\n",
      "litora: 5\n",
      "torquent: 5\n",
      "conubia: 5\n",
      "nostra: 5\n",
      "inceptos: 5\n",
      "himenaeos: 5\n",
      "blandit: 5\n",
      "vivamus: 4\n",
      "imperdiet: 4\n",
      "habitasse: 3\n",
      "platea: 3\n",
      "porttitor: 3\n",
      "adipiscing: 1\n",
      "primis: 1\n",
      "cubilia: 1\n",
      "natoque: 1\n",
      "penatibus: 1\n",
      "parturient: 1\n",
      "montes: 1\n",
      "nascetur: 1\n",
      "ridiculus: 1\n",
      "10 самых часто встречающихся слов:\n",
      "sit: 209\n",
      "nec: 129\n",
      "a: 97\n",
      "velit: 63\n",
      "lectus: 54\n",
      "duis: 51\n",
      "cras: 46\n",
      "amet: 44\n",
      "nisl: 41\n",
      "ante: 38\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from Levenshtein import distance\n",
    "\n",
    "\n",
    "# Функция чтения файла\n",
    "def read_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {filename} не найден.\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Функция получения уникальных слов\n",
    "def get_unique_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    unique_words = set(words)\n",
    "    return unique_words\n",
    "\n",
    "\n",
    "# Функция подсчета гласных и согласных\n",
    "def count_vowels_and_consonants(text):\n",
    "    vowels = 0\n",
    "    consonants = 0\n",
    "    for char in text.lower():\n",
    "        if char in string.ascii_letters:\n",
    "            if char in 'aeiouy':\n",
    "                vowels += 1\n",
    "            else:\n",
    "                consonants += 1\n",
    "    return vowels, consonants\n",
    "\n",
    "\n",
    "# Функция подсчета предложений и их длины\n",
    "def get_sentences_info(text):\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    number_of_sentences = len(sentences)\n",
    "    total_length_of_sentences = sum(len(re.findall(r'\\b\\w+\\b', sentence)) for sentence in sentences)\n",
    "    return number_of_sentences, total_length_of_sentences\n",
    "\n",
    "\n",
    "# Функция проверки схожести слов (по расстоянию Левенштейна)\n",
    "def are_words_similar(word1, word2, threshold=2):\n",
    "    return distance(word1, word2) <= threshold\n",
    "\n",
    "\n",
    "# Функция подсчета частоты слов с учетом схожести\n",
    "def get_word_frequency_with_similarity(text, threshold=2):\n",
    "    word_frequency = Counter()\n",
    "    processed_words = set()\n",
    "    for word in re.findall(r'\\b\\w+\\b', text.lower()):\n",
    "        word = word.strip()\n",
    "        found_similar = False\n",
    "        for processed_word in processed_words:\n",
    "            if are_words_similar(word, processed_word, threshold):\n",
    "                word_frequency[processed_word] += 1\n",
    "                found_similar = True\n",
    "                break\n",
    "        if not found_similar:\n",
    "            word_frequency[word] += 1\n",
    "            processed_words.add(word)\n",
    "    return word_frequency\n",
    "\n",
    "\n",
    "# Функция получения 10 самых часто встречающихся слов\n",
    "def get_top_10_words(word_frequency):\n",
    "    top_10_words = word_frequency.most_common(10)\n",
    "    return top_10_words\n",
    "\n",
    "\n",
    "# Функция основного кода\n",
    "def main():\n",
    "    # Загрузка текста\n",
    "    text = read_file('text.txt')\n",
    "\n",
    "    if text:\n",
    "        # Подсчет уникальных слов\n",
    "        unique_words = get_unique_words(text)\n",
    "        print(f\"Количество уникальных слов: {len(unique_words)}\")\n",
    "\n",
    "        # Подсчет гласных и согласных\n",
    "        vowels, consonants = count_vowels_and_consonants(text)\n",
    "        print(f\"Гласные: {vowels}\")\n",
    "        print(f\"Согласные: {consonants}\")\n",
    "\n",
    "        # Подсчет количества и длины предложений\n",
    "        number_of_sentences, total_length_of_sentences = get_sentences_info(text)\n",
    "        print(f\"Количество предложений: {number_of_sentences}\")\n",
    "        print(f\"Общая длина предложений: {total_length_of_sentences}\")\n",
    "\n",
    "        # Подсчет частоты слов с учетом схожести\n",
    "        word_frequency_with_similarity = get_word_frequency_with_similarity(text)\n",
    "        print(\"Частота слов с учетом схожести:\")\n",
    "        for word, count in word_frequency_with_similarity.most_common():\n",
    "            print(f\"{word}: {count}\")\n",
    "\n",
    "        # Получение 10 самых часто встречающихся слов\n",
    "        top_10_words = get_top_10_words(word_frequency_with_similarity)\n",
    "        print(\"10 самых часто встречающихся слов:\")\n",
    "        for word, count in top_10_words:\n",
    "            print(f\"{word}: {count}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d0207-e948-4f7b-aeb8-ee8e724a1583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
